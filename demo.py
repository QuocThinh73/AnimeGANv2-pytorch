import streamlit as st
import io
import os

# Try to import PyTorch and related libraries
try:
    import torch
    import torchvision.transforms as transforms
    from PIL import Image
    from models import AnimeGANGenerator
    TORCH_AVAILABLE = True
except ImportError as e:
    TORCH_AVAILABLE = False
    TORCH_ERROR = str(e)
except OSError as e:
    TORCH_AVAILABLE = False
    TORCH_ERROR = str(e)

# Page config
st.set_page_config(
    page_title="AnimeGANv2 Demo",
    page_icon="üé®",
    layout="wide"
)

# Title
st.title("üé® AnimeGANv2 - Chuy·ªÉn ·∫£nh th√†nh Anime")

st.markdown("Upload checkpoint G.pth v√† ·∫£nh ƒë·ªÉ t·∫°o ·∫£nh anime style!")

# Initialize session state
if 'model' not in st.session_state:
    st.session_state.model = None
if 'device' not in st.session_state:
    st.session_state.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")

# Sidebar for model loading
with st.sidebar:
    st.header("‚öôÔ∏è C√†i ƒë·∫∑t Model")
    
    # Option 1: Upload checkpoint file
    st.subheader("1. Upload Checkpoint")
    uploaded_checkpoint = st.file_uploader(
        "Ch·ªçn file G.pth",
        type=['pth'],
        help="Upload file checkpoint c·ªßa Generator (G.pth)"
    )
    
    # Option 2: Use default checkpoint
    st.subheader("2. Ho·∫∑c s·ª≠ d·ª•ng checkpoint m·∫∑c ƒë·ªãnh")
    default_checkpoint_path = "output/G.pth"
    use_default = st.checkbox("S·ª≠ d·ª•ng checkpoint m·∫∑c ƒë·ªãnh (output/G.pth)", value=False)
    
    # Load model button
    load_model = st.button("üîÑ Load Model", type="primary")
    
    if load_model:
        checkpoint_path = None
        
        if use_default and os.path.exists(default_checkpoint_path):
            checkpoint_path = default_checkpoint_path
            st.success(f"ƒêang s·ª≠ d·ª•ng checkpoint m·∫∑c ƒë·ªãnh: {default_checkpoint_path}")
        elif uploaded_checkpoint is not None:
            # Save uploaded file temporarily
            with open("temp_G.pth", "wb") as f:
                f.write(uploaded_checkpoint.getbuffer())
            checkpoint_path = "temp_G.pth"
            st.success("ƒê√£ upload checkpoint!")
        else:
            st.error("Vui l√≤ng upload checkpoint ho·∫∑c ch·ªçn s·ª≠ d·ª•ng checkpoint m·∫∑c ƒë·ªãnh!")
            checkpoint_path = None
        
        if checkpoint_path:
            try:
                with st.spinner("ƒêang load model..."):
                    # Initialize model
                    model = AnimeGANGenerator().to(st.session_state.device)
                    
                    # Load checkpoint
                    state_dict = torch.load(checkpoint_path, map_location=st.session_state.device)
                    model.load_state_dict(state_dict)
                    model.eval()
                    
                    # Save to session state
                    st.session_state.model = model
                    
                    st.success("‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng!")
                    
                    # Show device info
                    device_name = "GPU (CUDA)" if torch.cuda.is_available() else "CPU"
                    st.info(f"ƒêang s·ª≠ d·ª•ng: {device_name}")
                    
            except Exception as e:
                st.error(f"L·ªói khi load model: {str(e)}")
    
    # Clean up temp file
    if uploaded_checkpoint and os.path.exists("temp_G.pth"):
        pass  # Keep it for now, will be cleaned up later

# Main content area
col1, col2 = st.columns(2)

with col1:
    st.header("üì∏ ·∫¢nh g·ªëc")
    
    # Image upload
    uploaded_image = st.file_uploader(
        "Ch·ªçn ·∫£nh ƒë·ªÉ chuy·ªÉn ƒë·ªïi",
        type=['png', 'jpg', 'jpeg'],
        help="Upload ·∫£nh b·∫°n mu·ªën chuy·ªÉn th√†nh anime style"
    )
    
    if uploaded_image is not None:
        # Display original image
        image = Image.open(uploaded_image).convert('RGB')
        st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
        
        # Image info
        st.info(f"K√≠ch th∆∞·ªõc: {image.size[0]} x {image.size[1]} pixels")

with col2:
    st.header("üé® ·∫¢nh Anime")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng load model tr∆∞·ªõc (b√™n sidebar)")
    else:
        if uploaded_image is not None:
            # Inference button
            if st.button("‚ú® T·∫°o ·∫£nh Anime", type="primary"):
                try:
                    with st.spinner("ƒêang x·ª≠ l√Ω..."):
                        # Preprocess image
                        transform = transforms.Compose([
                            transforms.Resize((256, 256)),
                            transforms.ToTensor(),
                            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
                        ])
                        
                        # Convert PIL to tensor
                        image_tensor = transform(image).unsqueeze(0).to(st.session_state.device)
                        
                        # Inference
                        with torch.no_grad():
                            output = st.session_state.model(image_tensor)
                            
                            # Denormalize: from [-1, 1] to [0, 1]
                            output = output * 0.5 + 0.5
                            output = torch.clamp(output, 0, 1)
                            
                            # Convert to PIL Image
                            output_image = transforms.ToPILImage()(output.squeeze(0).cpu())
                            
                            # Display result
                            st.image(output_image, caption="·∫¢nh Anime", use_container_width=True)
                            
                            # Download button
                            buf = io.BytesIO()
                            output_image.save(buf, format='PNG')
                            st.download_button(
                                label="üíæ T·∫£i ·∫£nh v·ªÅ",
                                data=buf.getvalue(),
                                file_name="anime_result.png",
                                mime="image/png"
                            )
                            
                            st.success("‚úÖ Ho√†n th√†nh!")
                            
                except Exception as e:
                    st.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
                    st.exception(e)
        else:
            st.info("üëÜ Upload ·∫£nh ·ªü c·ªôt b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu")

# Footer
st.markdown("---")
st.markdown("### üìù H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:")
st.markdown("""
1. **Load Model**: 
   - Upload file G.pth ·ªü sidebar ho·∫∑c ch·ªçn s·ª≠ d·ª•ng checkpoint m·∫∑c ƒë·ªãnh
   - Click n√∫t "Load Model" ƒë·ªÉ load model v√†o memory

2. **Upload ·∫¢nh**: 
   - Ch·ªçn ·∫£nh b·∫°n mu·ªën chuy·ªÉn ƒë·ªïi (PNG, JPG, JPEG)

3. **T·∫°o ·∫¢nh Anime**: 
   - Click n√∫t "T·∫°o ·∫£nh Anime" ƒë·ªÉ th·ª±c hi·ªán inference
   - K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã ·ªü c·ªôt b√™n ph·∫£i
   - B·∫°n c√≥ th·ªÉ t·∫£i ·∫£nh k·∫øt qu·∫£ v·ªÅ m√°y

**L∆∞u √Ω**: 
- Model s·∫Ω ƒë∆∞·ª£c resize ·∫£nh v·ªÅ 256x256 pixels
- S·ª≠ d·ª•ng GPU s·∫Ω nhanh h∆°n CPU
- Model ch·ªâ c·∫ßn load 1 l·∫ßn, c√≥ th·ªÉ d√πng cho nhi·ªÅu ·∫£nh
""")

# Cleanup temp file on app restart
if os.path.exists("temp_G.pth"):
    try:
        os.remove("temp_G.pth")
    except:
        pass

