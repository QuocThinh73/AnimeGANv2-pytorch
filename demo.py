import streamlit as st
import io
import os
import pickle

# Try to import PyTorch and related libraries
try:
    import torch
    import torchvision.transforms as transforms
    from PIL import Image
    from models import AnimeGANGenerator
    TORCH_AVAILABLE = True
except ImportError as e:
    TORCH_AVAILABLE = False
    TORCH_ERROR = str(e)
except OSError as e:
    TORCH_AVAILABLE = False
    TORCH_ERROR = str(e)

# Helper function to load checkpoint with compatibility fixes
def load_checkpoint_compatible(checkpoint_path, device='cpu'):
    """
    Load checkpoint with multiple compatibility methods to handle
    PyTorch version mismatches, especially the _rebuild_device_tensor_from_cpu_tensor error.
    """
    # Fix: Monkey patch _rebuild_device_tensor_from_cpu_tensor if it doesn't exist
    # This handles the case where checkpoint was saved with newer PyTorch but loaded with older
    if not hasattr(torch._utils, '_rebuild_device_tensor_from_cpu_tensor'):
        def _rebuild_device_tensor_from_cpu_tensor(storage, device_str):
            """Fallback for missing _rebuild_device_tensor_from_cpu_tensor"""
            # Try to use _rebuild_tensor as fallback
            if hasattr(torch._utils, '_rebuild_tensor'):
                # Convert device string to device object
                device_obj = torch.device(device_str) if isinstance(device_str, str) else device_str
                return torch._utils._rebuild_tensor(storage, device_obj)
            else:
                # Last resort: return storage as tensor
                return storage
        torch._utils._rebuild_device_tensor_from_cpu_tensor = _rebuild_device_tensor_from_cpu_tensor
    
    # Method 1: Standard load with weights_only=False (PyTorch 2.0+)
    try:
        return torch.load(checkpoint_path, map_location=device, weights_only=False)
    except (AttributeError, RuntimeError, pickle.UnpicklingError, TypeError) as e:
        pass
    
    # Method 2: Load without weights_only (older PyTorch or compatibility)
    try:
        return torch.load(checkpoint_path, map_location=device)
    except (AttributeError, RuntimeError, pickle.UnpicklingError, TypeError) as e:
        pass
    
    # Method 3: Try loading with pickle_module explicitly
    try:
        return torch.load(checkpoint_path, map_location=device, pickle_module=pickle)
    except Exception as e:
        pass
    
    # If all methods fail, raise error with helpful message
    raise RuntimeError(
        f"Kh√¥ng th·ªÉ load checkpoint t·ª´ {checkpoint_path}. "
        "L·ªói c√≥ th·ªÉ do kh√¥ng t∆∞∆°ng th√≠ch phi√™n b·∫£n PyTorch. "
        "Th·ª≠ c√†i ƒë·∫∑t l·∫°i PyTorch v·ªõi phi√™n b·∫£n t∆∞∆°ng th√≠ch ho·∫∑c train l·∫°i model."
    )

# Page config
st.set_page_config(
    page_title="AnimeGANv2 Demo",
    page_icon="üé®",
    layout="wide"
)

# Title
st.title("üé® AnimeGANv2 - Chuy·ªÉn ·∫£nh th√†nh Anime")
st.markdown("Ch·ªçn checkpoint v√† upload ·∫£nh ƒë·ªÉ t·∫°o ·∫£nh anime style!")

# Initialize session state
if 'model' not in st.session_state:
    st.session_state.model = None
if 'device' not in st.session_state:
    st.session_state.device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
if 'selected_epoch' not in st.session_state:
    st.session_state.selected_epoch = None

# Function to scan available checkpoints
def scan_checkpoints():
    """Scan for available checkpoints in output/animegan/checkpoints/"""
    checkpoints_dir = "output/animegan/checkpoints"
    available_epochs = []
    
    if os.path.exists(checkpoints_dir):
        # Get all epoch directories
        for item in os.listdir(checkpoints_dir):
            epoch_dir = os.path.join(checkpoints_dir, item)
            if os.path.isdir(epoch_dir) and item.startswith("epoch_"):
                g_path = os.path.join(epoch_dir, "G.pth")
                if os.path.exists(g_path):
                    # Extract epoch number
                    try:
                        epoch_num = int(item.replace("epoch_", ""))
                        available_epochs.append({
                            'epoch': epoch_num,
                            'name': item,
                            'path': g_path
                        })
                    except ValueError:
                        continue
    
    # Sort by epoch number
    available_epochs.sort(key=lambda x: x['epoch'], reverse=True)
    return available_epochs

# Sidebar for model loading
with st.sidebar:
    st.header("‚öôÔ∏è C√†i ƒë·∫∑t Model")
    
    # Scan for available checkpoints
    available_checkpoints = scan_checkpoints()
    
    if not available_checkpoints:
        st.error("‚ùå Kh√¥ng t√¨m th·∫•y checkpoint n√†o!")
        st.info("Vui l√≤ng ƒë·∫£m b·∫£o c√≥ checkpoint trong `output/animegan/checkpoints/epoch_xxx/`")
    else:
        st.success(f"‚úÖ T√¨m th·∫•y {len(available_checkpoints)} checkpoint(s)")
        
        # Create list of epoch names for selectbox
        epoch_options = [f"Epoch {cp['epoch']:03d}" for cp in available_checkpoints]
        
        # Selectbox for choosing epoch
        selected_index = st.selectbox(
            "Ch·ªçn checkpoint:",
            options=range(len(epoch_options)),
            format_func=lambda x: epoch_options[x],
            help="Ch·ªçn epoch checkpoint b·∫°n mu·ªën s·ª≠ d·ª•ng"
        )
        
        selected_checkpoint = available_checkpoints[selected_index]
        st.info(f"üìÅ ƒê∆∞·ªùng d·∫´n: `{selected_checkpoint['path']}`")
        
        # Load model button
        load_model = st.button("üîÑ Load Model", type="primary")
        
        if load_model:
            checkpoint_path = selected_checkpoint['path']
            try:
                with st.spinner("ƒêang load model..."):
                    # Initialize model
                    model = AnimeGANGenerator().to(st.session_state.device)
                    
                    # Load checkpoint with compatibility handling
                    # Use helper function that tries multiple methods
                    state_dict = load_checkpoint_compatible(checkpoint_path, device='cpu')
                    
                    # Load state dict to model
                    model.load_state_dict(state_dict)
                    
                    # Move model to target device after loading
                    model = model.to(st.session_state.device)
                    model.eval()
                    
                    # Save to session state
                    st.session_state.model = model
                    st.session_state.selected_epoch = selected_checkpoint['epoch']
                    
                    st.success(f"‚úÖ Model ƒë√£ ƒë∆∞·ª£c load th√†nh c√¥ng! (Epoch {selected_checkpoint['epoch']:03d})")
                    
                    # Show device info
                    device_name = "GPU (CUDA)" if torch.cuda.is_available() else "CPU"
                    st.info(f"ƒêang s·ª≠ d·ª•ng: {device_name}")
                    
            except Exception as e:
                st.error(f"L·ªói khi load model: {str(e)}")
                st.exception(e)
                st.markdown("""
                **G·ª£i √Ω kh·∫Øc ph·ª•c:**
                - L·ªói n√†y th∆∞·ªùng do kh√¥ng t∆∞∆°ng th√≠ch phi√™n b·∫£n PyTorch
                - Th·ª≠ c√†i ƒë·∫∑t l·∫°i PyTorch v·ªõi phi√™n b·∫£n t∆∞∆°ng th√≠ch
                - Ho·∫∑c train l·∫°i model v·ªõi phi√™n b·∫£n PyTorch hi·ªán t·∫°i
                """)
        
        # Show current loaded model info
        if st.session_state.model is not None and st.session_state.selected_epoch is not None:
            st.markdown("---")
            st.success(f"‚úÖ Model hi·ªán t·∫°i: Epoch {st.session_state.selected_epoch:03d}")

# Main content area
col1, col2 = st.columns(2)

with col1:
    st.header("üì∏ ·∫¢nh g·ªëc")
    
    # Image upload
    uploaded_image = st.file_uploader(
        "Ch·ªçn ·∫£nh ƒë·ªÉ chuy·ªÉn ƒë·ªïi",
        type=['png', 'jpg', 'jpeg'],
        help="Upload ·∫£nh b·∫°n mu·ªën chuy·ªÉn th√†nh anime style"
    )
    
    if uploaded_image is not None:
        # Display original image
        image = Image.open(uploaded_image).convert('RGB')
        st.image(image, caption="·∫¢nh g·ªëc", use_container_width=True)
        
        # Image info
        st.info(f"K√≠ch th∆∞·ªõc: {image.size[0]} x {image.size[1]} pixels")

with col2:
    st.header("üé® ·∫¢nh Anime")
    
    if st.session_state.model is None:
        st.warning("‚ö†Ô∏è Vui l√≤ng load model tr∆∞·ªõc (b√™n sidebar)")
    else:
        if uploaded_image is not None:
            # Inference button
            if st.button("‚ú® T·∫°o ·∫£nh Anime", type="primary"):
                try:
                    with st.spinner("ƒêang x·ª≠ l√Ω..."):
                        # Preprocess image
                        transform = transforms.Compose([
                            transforms.Resize((256, 256)),
                            transforms.ToTensor(),
                            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))
                        ])
                        
                        # Convert PIL to tensor
                        image_tensor = transform(image).unsqueeze(0).to(st.session_state.device)
                        
                        # Inference
                        with torch.no_grad():
                            output = st.session_state.model(image_tensor)
                            
                            # Denormalize: from [-1, 1] to [0, 1]
                            output = output * 0.5 + 0.5
                            output = torch.clamp(output, 0, 1)
                            
                            # Convert to PIL Image
                            output_image = transforms.ToPILImage()(output.squeeze(0).cpu())
                            
                            # Display result
                            st.image(output_image, caption="·∫¢nh Anime", use_container_width=True)
                            
                            # Download button
                            buf = io.BytesIO()
                            output_image.save(buf, format='PNG')
                            st.download_button(
                                label="üíæ T·∫£i ·∫£nh v·ªÅ",
                                data=buf.getvalue(),
                                file_name="anime_result.png",
                                mime="image/png"
                            )
                            
                            st.success("‚úÖ Ho√†n th√†nh!")
                            
                except Exception as e:
                    st.error(f"L·ªói khi x·ª≠ l√Ω ·∫£nh: {str(e)}")
                    st.exception(e)
        else:
            st.info("üëÜ Upload ·∫£nh ·ªü c·ªôt b√™n tr√°i ƒë·ªÉ b·∫Øt ƒë·∫ßu")

# Footer
st.markdown("---")
st.markdown("### üìù H∆∞·ªõng d·∫´n s·ª≠ d·ª•ng:")
st.markdown("""
1. **Ch·ªçn v√† Load Model**: 
   - ·ªû sidebar, ch·ªçn checkpoint t·ª´ danh s√°ch c√°c epoch c√≥ s·∫µn
   - Click n√∫t "Load Model" ƒë·ªÉ load model v√†o memory
   - Checkpoint ƒë∆∞·ª£c t·ª± ƒë·ªông qu√©t t·ª´ `output/animegan/checkpoints/epoch_xxx/`

2. **Upload ·∫¢nh**: 
   - Ch·ªçn ·∫£nh b·∫°n mu·ªën chuy·ªÉn ƒë·ªïi (PNG, JPG, JPEG)

3. **T·∫°o ·∫¢nh Anime**: 
   - Click n√∫t "T·∫°o ·∫£nh Anime" ƒë·ªÉ th·ª±c hi·ªán inference
   - K·∫øt qu·∫£ s·∫Ω hi·ªÉn th·ªã ·ªü c·ªôt b√™n ph·∫£i
   - B·∫°n c√≥ th·ªÉ t·∫£i ·∫£nh k·∫øt qu·∫£ v·ªÅ m√°y

**L∆∞u √Ω**: 
- Model s·∫Ω ƒë∆∞·ª£c resize ·∫£nh v·ªÅ 256x256 pixels
- S·ª≠ d·ª•ng GPU s·∫Ω nhanh h∆°n CPU
- Model ch·ªâ c·∫ßn load 1 l·∫ßn, c√≥ th·ªÉ d√πng cho nhi·ªÅu ·∫£nh
- Checkpoint ƒë∆∞·ª£c s·∫Øp x·∫øp theo epoch (m·ªõi nh·∫•t ·ªü tr√™n)
""")

